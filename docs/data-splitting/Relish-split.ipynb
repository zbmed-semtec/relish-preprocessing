{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Data Splitting\n",
        "\n",
        "## Pre requisites\n",
        "1. A TSV file which contains PID1, PID2 and the corresponsing value of relvancy between the pairs of PIDs.\n",
        "2. The relish_tokenized.npy file with tokens. \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Loading Necessary Modules"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8Rr2G30pa_Wq"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "from sklearn.model_selection import ShuffleSplit\n",
        "from sklearn.model_selection import train_test_split\n",
        "from numpy import array\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Load the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "df_relish = pd.read_csv('/content/drive/MyDrive/Bonn/ZB Med/data/RELISH.tsv', sep='\\t')\n",
        "df_relish.columns=['PID1', 'PID2','Value']\n",
        "data = np.load('data/RELISH_tokenized.npy', allow_pickle=True)\n",
        "df_npy = pd.DataFrame(data)\n",
        "df_npy = pd.DataFrame(data, columns=['PID', 'Title', 'Abstract'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Converting PIDs to a list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FTFhMC-EgScv"
      },
      "outputs": [],
      "source": [
        "dfr_pid1=df_relish['PID1'].tolist()\n",
        "dfr_pid2=df_relish['PID2'].tolist()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hcDH2de-g3p-"
      },
      "outputs": [],
      "source": [
        "\n",
        "gt_pid=df_npy['PID'].tolist()\n",
        "gt_pid = [int(arr) for arr in gt_pid]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Declaration of memory variables for best and worst case."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YoJ21Pdcguvs"
      },
      "outputs": [],
      "source": [
        "train, test = train_test_split(df_npy, test_size=0.20, shuffle=True)\n",
        "train.to_csv('split/RELISH_NPY_Training_Dataset.tsv', sep='\\t', index=False)\n",
        "test.to_csv('split/RELISH_NPY_Test_Dataset.tsv', sep='\\t', index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Load the split dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iChRD3CtiMAZ"
      },
      "outputs": [],
      "source": [
        "\n",
        "dfnpy_train = pd.read_csv('split/RELISH_NPY_Training_Dataset.tsv', sep='\\t')\n",
        "dfnpy_test = pd.read_csv('plit/RELISH_NPY_Test_Dataset.tsv', sep='\\t')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Eg9jxmLjekOx"
      },
      "outputs": [],
      "source": [
        "dfnpy_train_pid=dfnpy_train['PID'].tolist()\n",
        "dfnpy_test_pid=dfnpy_test['PID'].tolist()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        " ## Find matching pairs of PID1 and PID2 between two datasets."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SXsQDahVsgJj"
      },
      "outputs": [],
      "source": [
        "def matching_pairs(df_rel, df_npy):\n",
        "    # Read data from the first file\n",
        "    file1_data_train = df_rel\n",
        "\n",
        "    # Read data from the second file\n",
        "    file2_data_train = df_npy\n",
        "\n",
        "    # Extract unique PIDs from both columns (PID1 and PID2) in the first file\n",
        "    pids_file1_train = set(file1_data_train['PID1']).union(set(file1_data_train['PID2']))\n",
        "\n",
        "    # Extract PIDs from the second file\n",
        "    pids_file2_train = set(file2_data_train['PID'])\n",
        "\n",
        "    # Find pairs from the first file where both PID1 and PID2 are present in the second file\n",
        "    matching_pairs_train = []\n",
        "\n",
        "    for _, row in file1_data_train.iterrows():\n",
        "        pid1 = row['PID1']\n",
        "        pid2 = row['PID2']\n",
        "\n",
        "        if pid1 in pids_file2_train and pid2 in pids_file2_train:\n",
        "            matching_pairs_train.append((pid1, pid2))\n",
        "\n",
        "    mtpr1 = (len(matching_pairs_train) / len(file1_data_train['PID1'])) * 100\n",
        "    return mtpr1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gT3Tdv7hsyku",
        "outputId": "6a5464dd-eeaf-4ef5-ccec-555c9e3fd0e6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Matching Pairs in training :  63.6376084220283\n",
            "Matching Pairs in testing :  4.014050757571768\n"
          ]
        }
      ],
      "source": [
        "print(\"Matching Pairs in training : \",matching_pairs(df_relish,dfnpy_train))\n",
        "print(\"Matching Pairs in testing : \",matching_pairs(df_relish,dfnpy_test))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##  Iterate to Find the best train and test datasets based on matching pairs and Save the best train and test datasets as TSV files."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4fn4BGIGvtQE"
      },
      "outputs": [],
      "source": [
        "perc=0\n",
        "best_train_set = None\n",
        "best_test_set = None\n",
        "list_perc=[]\n",
        "for i in range(1000):\n",
        "  # dfnpy_train, dfnpy_test=split_data(df_npy)\n",
        "  dfnpy_train, dfnpy_test = train_test_split(df_npy, test_size=0.20, shuffle=True)\n",
        "  #memory variables for best and worst case.\n",
        "  dfnpy_train.to_csv('split/RELISH_NPY_Training_Dataset.tsv', sep='\\t', index=False)\n",
        "  dfnpy_test.to_csv('split/RELISH_NPY_Test_Dataset.tsv', sep='\\t', index=False)\n",
        "\n",
        "  # Load the dataset\n",
        "  dfnpy_train = pd.read_csv('split/RELISH_NPY_Training_Dataset.tsv', sep='\\t')\n",
        "  dfnpy_test = pd.read_csv('split/RELISH_NPY_Test_Dataset.tsv', sep='\\t')\n",
        "\n",
        "  train_perc=matching_pairs(df_relish, dfnpy_train)\n",
        "  list_perc.append(train_perc)\n",
        "  if(train_perc>perc):\n",
        "    perc=train_perc\n",
        "    best_train_set=dfnpy_train.copy()\n",
        "    best_test_set=dfnpy_test.copy()\n",
        "\n",
        "best_train_set.to_csv('plit/best_train_80_new.tsv')\n",
        "best_test_set.to_csv('split/best_test_20_new.tsv')\n",
        "print(\"Best Match Percentage : \",perc)\n",
        "\n",
        "with open('split/percentage.txt', 'w') as file:\n",
        "  for index,item in enumerate(list_perc):\n",
        "    file.write(f\"Index {index}: {item}\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2DgvJvCPrjk_"
      },
      "outputs": [],
      "source": [
        "dfnpy_test = pd.read_csv('split/best_test_20.tsv', sep='\\t')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QtxnpezQE0iR"
      },
      "outputs": [],
      "source": [
        "def matching_pairs(df_rel, df_npy, output_tsv='split/matching_pairs_train_80_20.tsv'):\n",
        "\n",
        "    file1_data_train = df_rel \n",
        "\n",
        "    file2_data_train = df_npy \n",
        "\n",
        "    # Extract unique PIDs from both columns (PID1 and PID2) in the first file\n",
        "    pids_file1_train = set(file1_data_train['PID1']).union(set(file1_data_train['PID2']))\n",
        "\n",
        "    # Extract PIDs from the second file\n",
        "    pids_file2_train = set(file2_data_train['PID'])\n",
        "\n",
        "    # Find pairs from the first file where both PID1 and PID2 are present in the second file\n",
        "    matching_pairs_train = []\n",
        "\n",
        "    for _, row in file1_data_train.iterrows():\n",
        "        pid1 = row['PID1']\n",
        "        pid2 = row['PID2']\n",
        "\n",
        "        if pid1 in pids_file2_train and pid2 in pids_file2_train:\n",
        "            matching_pairs_train.append((pid1, pid2))\n",
        "\n",
        "    # Create a DataFrame for matching pairs\n",
        "    matching_pairs_df = pd.DataFrame(matching_pairs_train, columns=['PID1', 'PID2'])\n",
        "\n",
        "    # Save matching pairs to a TSV file\n",
        "    matching_pairs_df.to_csv(output_tsv, sep='\\t', index=False)\n",
        "\n",
        "    mtpr1 = (len(matching_pairs_train) / len(file1_data_train['PID1'])) * 100\n",
        "    return mtpr1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FV4wrk4Crdgj",
        "outputId": "d4fbf4d5-0c1c-4b7c-ff38-ff66c75b06cc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Matching Pairs in testing :  3.5290152356977718\n"
          ]
        }
      ],
      "source": [
        "print(\"Matching Pairs in training : \", matching_pairs(df_relish,dfnpy_train))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gDqaXVR04w7J"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "def matching_pairs(df_rel, df_npy, output_tsv='split/matching_pairs_relish_train.tsv'):\n",
        "    # Read data from the first file\n",
        "    file1_data_train = df_rel \n",
        "\n",
        "    # Read data from the second file\n",
        "    file2_data_train = df_npy \n",
        "\n",
        "    # Extract unique PIDs from both columns (PID1 and PID2) in the first file\n",
        "    pids_file1_train = set(file1_data_train['PID1']).union(set(file1_data_train['PID2']))\n",
        "\n",
        "    # Extract PIDs from the second file\n",
        "    pids_file2_train = set(file2_data_train['PID'])\n",
        "\n",
        "    # Find pairs from the first file where both PID1 and PID2 are present in the second file\n",
        "    matching_pairs_train = []\n",
        "\n",
        "    for _, row in file1_data_train.iterrows():\n",
        "        pid1 = row['PID1']\n",
        "        pid2 = row['PID2']\n",
        "\n",
        "        if pid1 in pids_file2_train and pid2 in pids_file2_train:\n",
        "            matching_pairs_train.append((pid1, pid2, row['Value']))  # Include 'Value' attribute\n",
        "\n",
        "    # Create a DataFrame for matching pairs\n",
        "    matching_pairs_df = pd.DataFrame(matching_pairs_train, columns=['PID1', 'PID2', 'Value'])  # Include 'Value' column\n",
        "\n",
        "    # Save matching pairs to a TSV file\n",
        "    matching_pairs_df.to_csv(output_tsv, sep='\\t', index=False)\n",
        "\n",
        "    mtpr1 = (len(matching_pairs_train) / len(file1_data_train)) * 100  # Calculate matching pairs ratio\n",
        "    return mtpr1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3WBweRIs9tSN"
      },
      "outputs": [],
      "source": [
        "df_best_train=pd.read_csv('split/best_train_20.tsv', sep='\\t')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AuXXmWbbQB_F"
      },
      "outputs": [],
      "source": [
        "print(\"Matching Pairs in relish train : \",matching_pairs(df_relish,df_best_train))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
